{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shubham/tv_opt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from colour.plotting import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.cave_dataset import CAVEDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cave_dataset import R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CAVEDataset(\"../datasets/data/CAVE\", None, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3, 31, bias=False)\n",
    "# model.weight = torch.nn.Parameter(R.T)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "model.train()\n",
    "mse = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, x_old, y, z, x_gt, lz, idx = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 31])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../artifacts/R.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04466786754962344\n"
     ]
    }
   ],
   "source": [
    "baseline_total = 0\n",
    "# lets check mse loss for R provided by other vendors\n",
    "for items in dataset:\n",
    "    c, x_old, y, z, x_gt, lz, idx = items\n",
    "    z_ipt = z.numpy()\n",
    "    Zd = torch.zeros(z.shape[0], y.shape[1], y.shape[2])\n",
    "    C, N1, N2 = Zd.shape\n",
    "    for c in range(Zd.shape[0]):\n",
    "        Zd[c, :, :] = torch.FloatTensor(cv2.resize(z_ipt[c, :, :], (N1, N2), interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    y_pred = (R.T @ Zd.reshape(C, -1)).reshape(y.shape[0], N1, N2)\n",
    "    loss = mse(y_pred, y)\n",
    "    baseline_total += loss.item()\n",
    "\n",
    "print(baseline_total/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04466786754962344\n"
     ]
    }
   ],
   "source": [
    "print(baseline_total/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 mse: 0.0549600964698654\n",
      "epoch 1 mse: 0.05061110012376538\n",
      "epoch 2 mse: 0.04662693220262344\n",
      "epoch 3 mse: 0.04302138054313568\n",
      "epoch 4 mse: 0.03976119606970595\n",
      "epoch 5 mse: 0.036813664536636606\n",
      "epoch 6 mse: 0.03414908878935071\n",
      "epoch 7 mse: 0.03174053650134458\n",
      "epoch 8 mse: 0.02956353942863643\n",
      "epoch 9 mse: 0.027595865880497374\n",
      "epoch 10 mse: 0.025817318873193402\n",
      "epoch 11 mse: 0.024209568223271232\n",
      "epoch 12 mse: 0.022755993404783882\n",
      "epoch 13 mse: 0.021441536131673135\n",
      "epoch 14 mse: 0.020252572229275338\n",
      "epoch 15 mse: 0.019176782878975455\n",
      "epoch 16 mse: 0.018203041158043422\n",
      "epoch 17 mse: 0.01732129970780359\n",
      "epoch 18 mse: 0.0165224948611397\n",
      "epoch 19 mse: 0.01579845159386213\n",
      "epoch 20 mse: 0.015141800780279132\n",
      "epoch 21 mse: 0.014545898938264985\n",
      "epoch 22 mse: 0.014004757162183523\n",
      "epoch 23 mse: 0.013512977237741534\n",
      "epoch 24 mse: 0.013065693595518287\n",
      "epoch 25 mse: 0.01265851823756328\n",
      "epoch 26 mse: 0.012287493204124846\n",
      "epoch 27 mse: 0.011949048986515174\n",
      "epoch 28 mse: 0.011639963996668275\n",
      "epoch 29 mse: 0.011357330663416248\n",
      "epoch 30 mse: 0.011098523749611698\n",
      "epoch 31 mse: 0.010861173504963517\n",
      "epoch 32 mse: 0.01064314094121353\n",
      "epoch 33 mse: 0.01044249394013045\n",
      "epoch 34 mse: 0.01025749037328821\n",
      "epoch 35 mse: 0.010086556789107047\n",
      "epoch 36 mse: 0.009928275920593968\n",
      "epoch 37 mse: 0.009781369285729643\n",
      "epoch 38 mse: 0.009644687229480881\n",
      "epoch 39 mse: 0.009517194470390677\n",
      "epoch 40 mse: 0.009397961100778328\n",
      "epoch 41 mse: 0.009286152592931803\n",
      "epoch 42 mse: 0.009181020844082993\n",
      "epoch 43 mse: 0.009081894899002062\n",
      "epoch 44 mse: 0.008988176732180784\n",
      "epoch 45 mse: 0.008899330752543531\n",
      "epoch 46 mse: 0.008814879800551213\n",
      "epoch 47 mse: 0.008734399139379652\n",
      "epoch 48 mse: 0.00865751109085977\n",
      "epoch 49 mse: 0.008583880316179533\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "best_mse_loss = baseline_total/len(dataset)\n",
    "for epoch in range(n_epochs):\n",
    "    total_mse_loss = 0\n",
    "    for items in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        c, x_old, y, z, x_gt, lz, idx = items\n",
    "        z_ipt = z.numpy()\n",
    "        Zd = torch.zeros(z.shape[0], y.shape[1], y.shape[2])\n",
    "        C, N1, N2 = Zd.shape\n",
    "        for c in range(Zd.shape[0]):\n",
    "            Zd[c, :, :] = torch.FloatTensor(cv2.resize(z_ipt[c, :, :], (N1, N2), interpolation=cv2.INTER_CUBIC))\n",
    "        Zd = Zd.permute(1, 2, 0).reshape(-1, C)[None, ...]\n",
    "        y_pred = model(Zd)\n",
    "        # y_pred = (newR @ Zd.reshape(C, -1)).reshape(*y.shape)\n",
    "        y_pred = y_pred.transpose(1, 2).reshape(1, y.shape[0], N1, N2)\n",
    "        loss = mse(y_pred, y[None, ...])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_mse_loss += loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch} mse: {total_mse_loss/len(dataset)}\")\n",
    "    # if total_mse_loss/len(dataset) < best_mse_loss:\n",
    "    #     best_mse_loss =  total_mse_loss/len(dataset)\n",
    "    #     print(\"saving ...\")\n",
    "    #     torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([864.0564, 526.5782, 336.3699, 284.4187, 251.4844, 186.3748, 214.7948,\n",
       "        203.3272, 310.8278, 326.6242, 238.5372, 262.8672, 188.4587, 243.5897,\n",
       "        257.0776, 413.8622, 392.3787, 251.6243, 202.8402, 413.3468, 354.0082,\n",
       "        410.7009, 391.6816, 463.2041, 323.3726, 373.5068, 298.7026, 258.7417,\n",
       "        331.5312, 166.2900, 178.5420])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z should be converted to have 31 bands\n",
    "y[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shubham/tv_opt/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SpectralAngleMapper` will save all targets and predictions in the buffer. For large datasets, this may lead to a large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/data/shubham/tv_opt/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `UniversalImageQualityIndex` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import (\n",
    "    compare_mpsnr,\n",
    "    compare_mssim,\n",
    "    find_rmse,\n",
    "    # compare_sam,\n",
    "    compare_ergas\n",
    ")\n",
    "from torchmetrics import SpectralAngleMapper\n",
    "from torchmetrics import ErrorRelativeGlobalDimensionlessSynthesis as ERGAS\n",
    "sam = SpectralAngleMapper()\n",
    "ergas = ERGAS(ratio=1/8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=31, bias=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R @z.reshape(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CAVEDataset(\"../datasets/data/CAVE\", None, mode=\"test\")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                        shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shubham/HSI-MSI-Image-Fusion/hmi_fusion/notebooks/../models/hip/quality_metrics/cal_ssim.py:26: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  return structural_similarity(org_img, pred_img, data_range=max_p, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Metric scores:\n",
      "psnr:63.85741291840228,\n",
      "ssim:0.9999998807907104,\n",
      "rmse:0.1621954462527922,\n",
      "sam:nan,\n",
      "ergas:11.812759121426483,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets check all the metrics from the learned R\n",
    "\n",
    "\n",
    "total_psnr, total_ssim, total_rmse, total_sam, total_ergas =0,0,0,0,0\n",
    "with torch.no_grad():\n",
    "    for items in test_dataset:\n",
    "        c, x_old, y, z, x, lz, idx = items\n",
    "\n",
    "        zc, N1, N2 = z.shape \n",
    "        x2 = (R @ z.reshape(zc, -1)).reshape(y.shape[0], N1, N2)\n",
    "    \n",
    "        x = x.squeeze()\n",
    "        x2 = x2.squeeze()\n",
    "        x = x.permute(1, 2, 0).detach().cpu().numpy()\n",
    "        x2 = x2.permute(1, 2, 0).detach().cpu().numpy()\n",
    "        \n",
    "        total_ssim += compare_mssim(x, x2)\n",
    "        rmse,  mse, rmse_per_band = find_rmse(x, x2)\n",
    "        total_rmse += rmse\n",
    "        total_psnr += compare_mpsnr(x, x2, mse)\n",
    "        s\n",
    "        total_ergas += compare_ergas(x, x2, sf, rmse_per_band)\n",
    "        # total_sam += compare_sam(x, x2)\n",
    "        # total_ergas += ergas(torch.from_numpy(x).permute(2, 0, 1)[None, ...], \n",
    "        #                     torch.from_numpy(x2).permute(2, 0, 1)[None, ...])\n",
    "        # total_ergas += compare_ergas(x, x2,1/sf, rmse_per_band)\n",
    "\n",
    "opt = f\"\"\"## Metric scores:\n",
    "psnr:{total_psnr/len(test_loader)},\n",
    "ssim:{total_ssim/len(test_loader)},\n",
    "rmse:{total_rmse/len(test_loader)},\n",
    "sam:{total_sam/len(test_loader)},\n",
    "ergas:{total_ergas/len(test_loader)},\n",
    "\"\"\"\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ = R.T @ (z.reshape(3, -1)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.0245))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_.min(), z_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(6.2440))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zm = z.reshape(3, -1)\n",
    "z_ = R.T @ ((zm - zm.min(-1).values[:, None] / zm.max(-1).values[:, None]))\n",
    "z_.min(), z_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.0319))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ = R.T @ (z.reshape(3, -1)/z.reshape(3, -1).max(1).values[:, None])\n",
    "z_.min(), z_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = R @ (y.reshape(31, -1)/y.reshape(31, -1).max(1).values[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0005), tensor(0.2005))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_.min(), y_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0004), tensor(0.1726))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.min(), y_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(6.2440))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_.min(), z_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample 512, 512, 3 to 64, 64, 3\n",
    "\n",
    "# def spectral_response_to_band(y, z):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspectral\n",
    "# pyspectral.rsr_reader.RelativeSpectralResponse() # wavelength to band number calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to have dowsampling loss better than L2(downsample(z, bicubic))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "791ac5f91178d75982b260816770b05d3e12e3c8007ae99834eb6e20b19e6a8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
